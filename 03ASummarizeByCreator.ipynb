{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757c4ff4-4c80-40b9-80ba-f3d89bfeb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "API_KEY = 'sk-bedceae2ceba437f944db22706354095'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967c739-0cd6-45ef-9405-7e60c8d4fa28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9898175-32a6-4bbc-b6de-b8d55b3d7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_creator_audience_interaction(api_client, all_comments, creator_id):\n",
    "    \"\"\"\n",
    "    all_comments: list of comment texts from latest videos of a creator\n",
    "    \"\"\"\n",
    "\n",
    "    comment_sample = all_comments\n",
    "\n",
    "    print(f\"Number of comments considered for {creator_id} = {len(comment_sample)}\")\n",
    "\n",
    "    user_prompt = '\\n'.join(comment_sample)\n",
    "    print(f'user prompt is {user_prompt}')\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an expert in social behavior analysis.\n",
    "\n",
    "The user will provide a list of YouTube comments taken from the most recent videos of a single creator.\n",
    "\n",
    "Your task is to summarize the overall tone, quality, diversity, and dynamics of the audience interaction with the creator’s content **across these videos**.\n",
    "\n",
    "Your output must be in JSON format with the following keys:\n",
    "\n",
    "{\n",
    "  \"audience_sentiment_overview\": {\"positive\": X, \"neutral\": Y, \"negative\": Z},\n",
    "  \"common_emotions_expressed\": [...],\n",
    "  \"overall_audience_behavior_summary\": \"...\",\n",
    "  \"recurrent_themes\": [...],\n",
    "  \"bias_or_group_mentions\": [...],\n",
    "  \"is_sarcasm_common\": true/false,\n",
    "  \"languages_used\": [...],\n",
    "  \"spam_or_toxicity_prevalence\": \"low/medium/high\",\n",
    "  \"concluding_summary\": \"...\"\n",
    "}\n",
    "\n",
    "Keep it balanced and based on what is observable from the comments. Avoid making assumptions beyond the text.\n",
    "\"\"\"\n",
    "\n",
    "    response = api_client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format={'type': 'json_object'}\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    result[\"creator_id\"] = creator_id\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d052a32-7fda-4bbc-89ae-a99707ab6ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@smiletojannah (47, 5)\n",
      "(10, 5)\n",
      "✅ Already summarized for same videos for creator: @smiletojannah\n",
      "@thedeshbhakt (61, 5)\n",
      "(10, 5)\n",
      "✅ Already summarized for same videos for creator: @thedeshbhakt\n",
      "@MuslimSkeptic (60, 5)\n",
      "(10, 5)\n",
      "✅ Already summarized for same videos for creator: @MuslimSkeptic\n",
      "No new summaries generated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ANALYZED_COMMENTS_DIR = 'analyzed_comments'\n",
    "analyzed_comments_file_path = f'{ANALYZED_COMMENTS_DIR}/analyzed_comments.csv'\n",
    "df_analysis=pd.read_csv(analyzed_comments_file_path)    \n",
    "\n",
    "\n",
    "\n",
    "SUMMARIZED_PATH = \"summarized_analyzed_comments/summarized_analyzed.csv\"\n",
    "\n",
    "# Load both datasets\n",
    "df_summary = pd.read_csv(SUMMARIZED_PATH) if os.path.exists(SUMMARIZED_PATH) else pd.DataFrame(columns=[\"timestamp\", \"creator_id\", \"summarized_video_ids\", \"summary_analysis\"])\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "# Process each creator\n",
    "new_entries = []\n",
    "for creator_id in df_analysis[\"creator_id\"].unique():\n",
    "    df_creator = df_analysis[df_analysis[\"creator_id\"] == creator_id].sort_values(\"timestamp\", ascending=False)\n",
    "    print(creator_id,df_creator.shape)\n",
    "    latest_n = min(10, int(0.9 * len(df_creator)))\n",
    "    df_latest = df_creator.head(latest_n)\n",
    "    print(df_latest.shape)\n",
    "\n",
    "    current_ids = sorted(df_latest[\"id\"].tolist())\n",
    "\n",
    "    # Check if already summarized with this ID set\n",
    "    if not df_summary[df_summary[\"creator_id\"] == creator_id].empty:\n",
    "        existing = list(df_summary[df_summary[\"creator_id\"] == creator_id][\"summarized_video_ids\"])[0]\n",
    "        if existing=='_*_'.join(current_ids):\n",
    "            print(f\"✅ Already summarized for same videos for creator: {creator_id}\")\n",
    "            continue\n",
    "\n",
    "    # Gather comments\n",
    "    all_comments = []\n",
    "    for analysis_json in df_latest[\"analysis\"]:\n",
    "        try:\n",
    "            parsed = json.loads(analysis_json)            \n",
    "            all_comments.append(json.dumps(parsed))\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing comments for creator {creator_id}: {e}\")\n",
    "\n",
    "    if not all_comments:\n",
    "        print(f\"⚠️ No comments found for creator {creator_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Summarize\n",
    "    try:\n",
    "        summary = summarize_creator_audience_interaction(client, all_comments, creator_id)\n",
    "        \n",
    "        current_ids_str='_*_'.join(current_ids)\n",
    "        new_entries.append({\n",
    "            \"timestamp\": time.time(),\n",
    "            \"creator_id\": creator_id,\n",
    "            \"summarized_video_ids\": current_ids_str,\n",
    "            \"summary_analysis\": json.dumps(summary)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed summarization for {creator_id}: {e}\")\n",
    "\n",
    "# Save updates\n",
    "if new_entries:\n",
    "    df_new = pd.DataFrame(new_entries)\n",
    "    df_combined = pd.concat([df_summary, df_new], ignore_index=True)\n",
    "    df_combined.to_csv(SUMMARIZED_PATH, index=False)\n",
    "    print(f\"✅ Saved to {SUMMARIZED_PATH}\")\n",
    "else:\n",
    "    print(\"No new summaries generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d184db7-0823-4fce-bd33-f452ee4e3618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310k",
   "language": "python",
   "name": "py310k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
